import os
from pathlib import Path

import numpy as np
from PIL import Image
from paddleocr import PaddleOCR
import multiprocessing
import layoutparser as lp

num_cores = os.cpu_count()
print(f"å¤šæ ¸ CPUï¼Œå…± {num_cores} æ ¸")

# ------------------------
# ğŸ”¹ åˆå§‹åŒ– OCR
# ------------------------
ocr = PaddleOCR(
    lang="ch",
    use_angle_cls=False,  # âŒ CPU å¾ˆæ…¢ï¼Œå…ˆé—œ
    enable_mkldnn=True,  # âœ… ä¸€å®šè¦é–‹
    rec_batch_num=96,  # âœ… CPU ååé—œéµ
    text_det_box_thresh=0.6,  # è¼•å¾®æ”¾å¯¬
    text_det_thresh=0.3,  # è¼•é‡æ¨¡å‹å»ºè­°
    ocr_version="PP-OCRv3"
)

# ------------------------
# ğŸ”¹ LayoutParser å»¶é²åˆå§‹åŒ–
# ------------------------
_layout_model = None


def get_layout_model():
    """å»¶é²åˆå§‹åŒ– LayoutParser æ¨¡å‹ï¼Œé¿å… uvicorn spawn å•é¡Œ"""
    global _layout_model
    _layout_model = lp.PaddleDetectionLayoutModel(
        model_path="lp://PP-DocLayout/ppyolov3_mobilenet_v3",
        label_map={
            0: "Text",
            1: "Title",
            2: "List",
            3: "Table",
            4: "Figure"
        },
        device="cpu",
        extra_config={
            "score_thresh": 0.3  # CPU + æ–‡ä»¶å¯¦å‹™å»ºè­°å€¼
        }
    )
    return _layout_model


# ------------------------
# ğŸ”¹ æ”¯æ´åœ–ç‰‡æ ¼å¼
# ------------------------
IMAGE_EXTENSIONS = [".png", ".jpg", ".jpeg", ".tiff"]


# ------------------------
# ğŸ”¹ å–®å¼µ OCR
# ------------------------
def _ocr_single(img_path: Path) -> str:
    if not img_path.exists():
        return ""

    img = Image.open(img_path).convert("RGB")
    img.thumbnail((1200, 1200))
    import numpy as np
    img_np = np.array(img)

    result = ocr.ocr(img_np)

    # v3/v4/v5 å…¼å®¹
    if isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict):
        rec_texts = result[0].get('rec_texts', [])
    else:
        rec_texts = [line[1][0] for line in result]

    return "\n".join(rec_texts)


# ------------------------
# ğŸ”¹ å¤šåœ– OCR
# ------------------------
def ocr_images(img_paths: list[Path]) -> str:
    """æ”¯æ´å–®å¼µæˆ–å¤šå¼µåœ–ç‰‡ï¼Œå¤šåœ–ä½¿ç”¨å¤šç·šç¨‹åŠ é€Ÿ"""
    if len(img_paths) == 1:
        return _ocr_single(img_paths[0])

    max_workers = min(len(img_paths), multiprocessing.cpu_count())
    from concurrent.futures import ThreadPoolExecutor
    texts = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        for text in executor.map(_ocr_single, img_paths):
            texts.append(text)
    return "\n".join(texts).strip()


# ------------------------
# ğŸ”¹ Layout åˆ†ææ¥å£
# ------------------------
def layout_analyze(img_path: Path):
    """è¿”å› LayoutParser çš„å€å¡Šåˆ—è¡¨"""
    if not img_path.exists():
        return []

    img = Image.open(img_path).convert("RGB")
    img_np = np.array(img)

    model = get_layout_model()
    layout = model.detect(img_np)
    return layout  # LayoutBlock åˆ—è¡¨ï¼Œå¯é€²ä¸€æ­¥æ“ä½œ
